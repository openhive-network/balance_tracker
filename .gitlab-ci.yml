stages:
 - lint
 - build
 - test
 - cleanup

variables:
  # Variables required by Common CI jobs
  CI_COMMON_JOB_VERSION: "27bf7a315f3cacdf45336501112e6ac414d39006"
  DOCKER_BUILDER_TAG: "$CI_COMMON_JOB_VERSION"
  DOCKER_DIND_TAG: "$CI_COMMON_JOB_VERSION"
  IMAGE_REMOVER_TAG: "$CI_COMMON_JOB_VERSION"
  # Git configuration
  GIT_STRATEGY: clone
  GIT_SUBMODULE_STRATEGY: recursive
  # HAF configuration
  DATA_CACHE_HAF_TEMPLATE: /cache/replay_data_balance_tracker_haf
  DATA_CACHE_HAF: "/cache/replay_data_balance_tracker_haf_${CI_PIPELINE_ID}"
  BLOCK_LOG_SOURCE_DIR_5M: /blockchain/block_log_5m

include:
  - template: Workflows/Branch-Pipelines.gitlab-ci.yml
  - project: hive/haf
    ref: d3fc2e24303b4d392715d56350444dc478732979 # develop
    file: /scripts/ci-helpers/prepare_data_image_job.yml

.lint_job:
  stage: lint
  variables:
    GIT_SUBMODULE_STRATEGY: none
  artifacts:
    name: lint-results
    when: always
    expire_in: 24 hours
  tags:
    - public-runner-docker

lint_bash_scripts:
  extends: .lint_job
  image: koalaman/shellcheck-alpine:latest
  before_script:
    - apk add xmlstarlet
  script:
    - find . -name .git -type d -prune -o -type f -name \*.sh -print0 | xargs -0 -r -n1 shellcheck > shellcheck-checkstyle-result.xml 
  after_script:
    - xmlstarlet tr misc/checkstyle2junit.xslt shellcheck-checkstyle-result.xml > shellcheck-junit-result.xml
  artifacts:
    paths: 
      - shellcheck-checkstyle-result.xml
      - shellcheck-junit-result.xml
    reports:
      junit: shellcheck-junit-result.xml

lint_sql_scripts:
  extends: .lint_job
  image: 
    name: sqlfluff/sqlfluff:2.1.4
    entrypoint: [""]
  script:
    - sqlfluff lint --format yaml --write-output sql-lint.yaml
  artifacts:
    paths:
      - sql-lint.yaml

prepare_haf_image:
  stage: build
  extends: .prepare_haf_image
  variables:
    SUBMODULE_DIR: "$CI_PROJECT_DIR/haf"
    REGISTRY_USER: "$HAF_DEPLOY_USERNAME"
    REGISTRY_PASS: "$HAF_DEPLOY_TOKEN"
  before_script:
    - git config --global --add safe.directory $CI_PROJECT_DIR/haf
  tags:
    - public-runner-docker

prepare_haf_data:
  extends: .prepare_haf_data_5m
  needs:
    - job: prepare_haf_image
      artifacts: true
  stage: build
  variables:
    SUBMODULE_DIR: "$CI_PROJECT_DIR/haf"
    BLOCK_LOG_SOURCE_DIR: $BLOCK_LOG_SOURCE_DIR_5M
    CONFIG_INI_SOURCE: "$CI_PROJECT_DIR/docker/haf/config_5M.ini"
  tags:
    - data-cache-storage

.docker-base-build-template:
  extends: .docker_image_builder_job_template
  stage: build
  variables:
    BASE_REPO_NAME: base
    BASE_TAG: ubuntu-22.04-1
    NAME: ""
    TARGET: "$NAME-base"
  before_script:
    - !reference [.docker_image_builder_job_template, before_script]
    - |
      echo -e "\e[0Ksection_start:$(date +%s):login[collapsed=true]\r\e[0KLogging to Docker registry..."
      docker login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" $CI_REGISTRY
      echo -e "\e[0Ksection_end:$(date +%s):login\r\e[0K"
  script:
    - |
      echo -e "\e[0Ksection_end:$(date +%s):tag\r\e[0K"
      echo -e "\e[0Ksection_start:$(date +%s):build[collapsed=true]\r\e[0KBaking $NAME${BASE_REPO_NAME:+/$BASE_REPO_NAME} image..."
      function image-exists() {
        local image=$1
        docker manifest inspect "$1" > /dev/null
        return $?
      }
      if image-exists "$CI_REGISTRY_IMAGE/$NAME${BASE_REPO_NAME:+/$BASE_REPO_NAME}:$BASE_TAG"; then
        echo "Image $NAME${BASE_REPO_NAME:+/$BASE_REPO_NAME}:$BASE_TAG already exists. Skipping..."
      else
        echo "Baking $NAME${BASE_REPO_NAME:+/$BASE_REPO_NAME} base image..."
        git config --global --add safe.directory $(pwd)
        docker buildx bake --progress=plain --provenance=false --push "$TARGET"
      fi
      echo -e "\e[0Ksection_end:$(date +%s):build\r\e[0K"
  tags:
    - public-runner-docker

docker-backend-base-build:
  extends: .docker-base-build-template
  variables:
    NAME: "backend"

docker-frontend-base-build:
  extends: .docker-base-build-template
  variables:
    NAME: "frontend"

docker-ci-runner-build:
  extends: .docker-base-build-template
  variables:
    BASE_REPO_NAME: ""
    NAME: "ci-runner"
    TARGET: "ci-runner-ci"

docker-build:
  extends: .docker_image_builder_job_template
  stage: build
  needs:
   - docker-backend-base-build
   - docker-frontend-base-build
  before_script:
    - !reference [.docker_image_builder_job_template, before_script]
    - |
      echo -e "\e[0Ksection_start:$(date +%s):login[collapsed=true]\r\e[0KLogging to Docker registry..."
      docker login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" $CI_REGISTRY
      echo -e "\e[0Ksection_end:$(date +%s):login\r\e[0K"
  script:
    - |
      echo -e "\e[0Ksection_start:$(date +%s):tag[collapsed=true]\r\e[0KDetermining tag for the new image..."
      if [[ "$CI_COMMIT_BRANCH" == "$CI_DEFAULT_BRANCH" ]]; then
        echo "Running on default branch '$CI_DEFAULT_BRANCH': tag = 'latest'"
        export TAG="latest"
      else
        echo "Running on branch '$CI_COMMIT_BRANCH': tag = $CI_COMMIT_REF_SLUG"
        export TAG="$CI_COMMIT_REF_SLUG"
      fi
      echo -e "\e[0Ksection_end:$(date +%s):tag\r\e[0K"
      echo -e "\e[0Ksection_start:$(date +%s):build[collapsed=true]\r\e[0KBaking frontend and backend images..."
      git config --global --add safe.directory $(pwd)
      docker buildx bake --progress=plain --provenance=false --push ci
      echo -e "\e[0Ksection_end:$(date +%s):build\r\e[0K"
  tags:
    - public-runner-docker

test:
  extends: .docker_image_builder_job_template
  stage: test
  image: registry.gitlab.syncad.com/hive/balance_tracker/ci-runner:docker-24.0.1-2
  needs:
    - prepare_haf_image
    - docker-build
    - docker-ci-runner-build
  variables:
    POSTGRESS_ACCESS: postgresql://haf_admin@docker:5432/haf_block_log
    COMMAND: SELECT CASE WHEN irreversible_block = 5000000 THEN 0 ELSE 1 END FROM hive.contexts WHERE name = 'btracker_app';
    MESSAGE: Waiting for Balance Tracker to finish processing blocks...
    COMPOSE_OPTIONS_STRING: --project-name balance-tracker --env-file .env.local --file docker-compose.yml --file ci/docker-compose.yml --ansi never
  timeout: 2 hours
  before_script:
    - |
      echo -e "\e[0Ksection_start:$(date +%s):login[collapsed=true]\r\e[0KLogging to Docker registry..."
      docker login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" $CI_REGISTRY
      echo -e "\e[0Ksection_end:$(date +%s):login\r\e[0K"
      echo -e "\e[0Ksection_start:$(date +%s):git[collapsed=true]\r\e[0KConfiguring Git..."
      git config --global --add safe.directory "$CI_PROJECT_DIR"
      git config --global --add safe.directory "$CI_PROJECT_DIR/haf"
      echo -e "\e[0Ksection_end:$(date +%s):git\r\e[0K"
  script:
    - |
      echo -e "\e[0Ksection_start:$(date +%s):compose[collapsed=true]\r\e[0KStarting the test environment..."

      cp /blockchain/block_log_5m/block_log docker/blockchain/block_log
      chmod a+w docker/blockchain/block_log

      pushd haf
      HAF_COMMIT=$(git rev-parse HEAD)
      popd
      pushd docker
      {
        echo "HAF_REGISTRY=registry.gitlab.syncad.com/hive/haf/instance"
        echo "HAF_VERSION=instance-$HAF_COMMIT"
        echo "BACKEND_VERSION=$CI_COMMIT_SHA"
        echo "FRONTEND_VERSION=$CI_COMMIT_SHA"
        echo "HIVED_UID=0"
        echo "PGHERO_USERNAME=unused"
        echo "PGHERO_PASSWORD=unused"
      } > .env.local
      cat .env.local
      IFS=" " read -ra COMPOSE_OPTIONS <<< $COMPOSE_OPTIONS_STRING
      docker compose "${COMPOSE_OPTIONS[@]}" up --detach #--exit-code-from haf
      popd

      echo -e "\e[0Ksection_end:$(date +%s):compose\r\e[0K"
      echo -e "\e[0Ksection_start:$(date +%s):wait[collapsed=true]\r\e[0K$MESSAGE"

      until psql "$POSTGRESS_ACCESS" --quiet --tuples-only --command="$COMMAND" | grep 0 &>/dev/null
      do 
        echo "$MESSAGE"
        sleep 3
      done

      echo -e "\e[0Ksection_end:$(date +%s):wait\r\e[0K"
      echo -e "\e[0Ksection_start:$(date +%s):tests[collapsed=true]\r\e[0KRunning tests..."

      ./balance-tracker.sh run-tests --backend-host=docker
      tar -czvf tests/performance/results.tar.gz $(pwd)/tests/performance/*result.*
      cat jmeter.log | python3 docker/ci/parse-jmeter-output.py
      m2u --input $(pwd)/tests/performance/result.xml --output $(pwd)/tests/performance/junit-result.xml

      echo -e "\e[0Ksection_end:$(date +%s):tests\r\e[0K"
  after_script:
    - |
      echo -e "\e[0Ksection_start:$(date +%s):compose2[collapsed=true]\r\e[0KStopping test environment..."

      pushd docker
      IFS=" " read -ra COMPOSE_OPTIONS <<< $COMPOSE_OPTIONS_STRING
      docker compose "${COMPOSE_OPTIONS[@]}" logs haf > haf.log
      docker compose "${COMPOSE_OPTIONS[@]}" logs backend-block-processing > backend-block-processing.log
      docker compose "${COMPOSE_OPTIONS[@]}" logs backend-postgrest > backend-postgrest.log
      docker compose "${COMPOSE_OPTIONS[@]}" logs frontend > frontend.log
      docker compose "${COMPOSE_OPTIONS[@]}" down --volumes
      popd

      tar -czvf docker/container-logs.tar.gz $(pwd)/docker/*.log

      echo -e "\e[0Ksection_end:$(date +%s):compose2\r\e[0K"
  artifacts:
    paths:
      - docker/container-logs.tar.gz
      - tests/performance/result_report/
      - tests/performance/results.tar.gz
      - jmeter.log
    reports:
      junit: tests/performance/junit-result.xml
    expire_in: 1 week
    when: always
  tags:
    - data-cache-storage

cleanup_haf_cache_manual:
  extends: .cleanup_cache_manual
  stage: cleanup
  variables:
    CLEANUP_PATH_PATTERN: "${DATA_CACHE_HAF_TEMPLATE}_*"
  resource_group: ${CI_COMMIT_SHA}
  tags:
    - data-cache-storage
